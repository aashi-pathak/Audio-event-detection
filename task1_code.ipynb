{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "HN-frYGYPD3t"
   },
   "outputs": [],
   "source": [
    "import librosa                                     \n",
    "import numpy as np\n",
    "import pdb\n",
    "import string\n",
    "from Levenshtein import distance\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import keras\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "eDIdesLWQmb7"
   },
   "outputs": [],
   "source": [
    "##################################################################### Utilis #################################################################\n",
    "def wav2feat(wavfile):\n",
    "    '''\n",
    "    Input: audio wav file name\n",
    "    Output: Magnitude spectrogram\n",
    "    '''\n",
    "    x, Fs = librosa.load(wavfile, sr=44100, mono=True) \n",
    "    hop = int(0.01 * Fs) # 10ms\n",
    "    win = int(0.02 * Fs) # 20ms\n",
    "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\n",
    "    return np.abs(X)\n",
    "\n",
    "def wavs2feat(wavfiles):\n",
    "    '''\n",
    "    Concatenate the audio files listed in wavfiles\n",
    "    Input: list of audio wav file names\n",
    "    Output: Magnitude spectrogram of concatenated wav\n",
    "    '''\n",
    "    x = []\n",
    "    for wf in wavfiles:\n",
    "        x1, Fs = librosa.load(wf, sr=44100, mono=True)\n",
    "        x.append(x1)\n",
    "    x = np.hstack(x)\n",
    "    hop = int(0.01 * Fs) # 10ms\n",
    "    win = int(0.02 * Fs) # 20ms\n",
    "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\n",
    "    return np.abs(X)\n",
    "\n",
    "def read_csv(filename):\n",
    "    id_label = {}\n",
    "    with open(filename,'r') as fid:\n",
    "        for line in fid: # '176787-5-0-27.wav,engine_idling\\n'\n",
    "            tokens = line.strip().split(',') # ['176787-5-0-27.wav', 'engine_idling']\n",
    "            id_label[tokens[0]] = tokens[1]\n",
    "    return id_label\n",
    "\n",
    "def editDistance(gt, est):\n",
    "    '''both are lists of labels\n",
    "    E.g. gt is \"dog_bark-street_music-engine_idling\"\n",
    "    E.g. est is \"street_music-engine_idling\"\n",
    "    '''\n",
    "    gttokens = gt.split('-')\n",
    "    esttokens = est.split('-')\n",
    "    # Map token to char\n",
    "    tokenset = list(set(gttokens+esttokens)) # ['dog_bark', 'siren', 'street_music', 'engine_idling']\n",
    "    token_char = {}\n",
    "    for i in range(len(tokenset)):\n",
    "        token_char[tokenset[i]] = string.ascii_uppercase[i]  # {'dog_bark': 'A', 'siren': 'B', 'street_music': 'C', 'engine_idling': 'D'}\n",
    "    # convert gt and est to strings\n",
    "    gtstr = [token_char[t] for t in gttokens]\n",
    "    gtstr = ''.join(gtstr)  # 'BCA'\n",
    "    eststr = [token_char[t] for t in esttokens]\n",
    "    eststr = ''.join(eststr)  # \n",
    "    # Compare\n",
    "    editdist = distance(gtstr, eststr) # 1\n",
    "    score = 1 - editdist/len(gtstr)\n",
    "    return editdist, score\n",
    "\n",
    "def evals(gtcsv, estcsv, taskid):\n",
    "    gt_id_label = read_csv(gtcsv)\n",
    "    est_id_label = read_csv(estcsv)\n",
    "    score = 0\n",
    "    for id in est_id_label:\n",
    "        if taskid==1:\n",
    "            if est_id_label[id] == gt_id_label[id]:\n",
    "                score += 1\n",
    "        elif taskid==2:\n",
    "            _, ss = editDistance(gt_id_label[id], est_id_label[id])\n",
    "            score += ss\n",
    "        else:\n",
    "            pdb.set_trace()\n",
    "            assert False, [\"taskid not correct; it is\", taskid]\n",
    "    avgScore = score/len(est_id_label)\n",
    "    return avgScore\n",
    "\n",
    "#######################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "GimvnqWtPD32"
   },
   "outputs": [],
   "source": [
    "# make list of file names\n",
    "import glob          \n",
    "file_names = glob.glob(\"../shared_train/audio_train/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "x9tn8XuVPD34"
   },
   "outputs": [],
   "source": [
    "n= len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do feature extraction with wav2feat and append it in a list X\n",
    "X=[]\n",
    "for a in file_names:\n",
    "    X.append(wav2feat(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNgVKVhCPD4C"
   },
   "outputs": [],
   "source": [
    "# do padding of each vector in X\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i]=np.pad(X[i], ((0,0),(0,401-X[i].shape[1])), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "P_KfW5_APD4E"
   },
   "outputs": [],
   "source": [
    "# make list of all output\n",
    "\n",
    "dic = read_csv('../shared_train/labels_train.csv')\n",
    "y=[]\n",
    "for key in dic:\n",
    "    y.append(dic[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Kn8tHYuwPD4K"
   },
   "outputs": [],
   "source": [
    "#  here l is dictionary which maps all labels with corresponding numbers eg- dog_bark: 0\n",
    "# and Y is list of output\n",
    "\n",
    "dic = read_csv('../shared_train/labels_train.csv')\n",
    "Y=[]\n",
    "l={}\n",
    "i=0\n",
    "for key in dic:\n",
    "    i=i+1\n",
    "    if i==1: continue\n",
    "    Y.append(dic[key])\n",
    "    l[dic[key]]=0\n",
    "i=0\n",
    "for key in l:\n",
    "    if l[key]==0: i=i+1\n",
    "    l[key]=i-1\n",
    "    \n",
    "y = np.zeros((len(Y),1))\n",
    "for i in range(len(Y)):\n",
    "    y[i] = l[Y[i]]\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RpH2q23J47vV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dog_bark',\n",
       " 1: 'gun_shot',\n",
       " 2: 'engine_idling',\n",
       " 3: 'siren',\n",
       " 4: 'jackhammer',\n",
       " 5: 'drilling',\n",
       " 6: 'children_playing',\n",
       " 7: 'street_music',\n",
       " 8: 'air_conditioner',\n",
       " 9: 'car_horn'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dictionary which maps numbers to corresponding class eg- 0: dog_bark\n",
    "\n",
    "dict_y={}\n",
    "for key in l:\n",
    "  dict_y[l[key]]=key\n",
    "dict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "783OYQ1YPD4Q"
   },
   "outputs": [],
   "source": [
    "# function of converting y to one hot vector\n",
    "\n",
    "def one_hot_encoding(y):\n",
    "    \n",
    "    y_1hot=np.zeros((len(y),n_classes))\n",
    "    for i in range(len(y)):\n",
    "        y_1hot[i,int(y[i])]=1\n",
    "\n",
    "    return y_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BOSOOQ5PD4R"
   },
   "outputs": [],
   "source": [
    "y=one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHgboqwnPD4R"
   },
   "outputs": [],
   "source": [
    "# spliting data into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhI2__MSPD4S"
   },
   "outputs": [],
   "source": [
    "# defining features used to train a model\n",
    "\n",
    "n_features=X[0].shape[0]\n",
    "max_length=X[0].shape[1]\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "dropout = 0.3\n",
    "\n",
    "input_shape = (n_features, max_length)\n",
    "steps_per_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcjJXooNPD4T"
   },
   "outputs": [],
   "source": [
    "# defining the model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=input_shape,dropout=dropout))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb2Ih7CyPD4T",
    "outputId": "4a63b4f4-e1a1-4d10-c81b-8dc499d6ad5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 513, 256)          673792    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131328)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16810112  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 17,485,194\n",
      "Trainable params: 17,485,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compiling the model\n",
    "# due to callback the model will be saved once it runs\n",
    "\n",
    "opt = Adam(lr=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "metrics=['accuracy'])\n",
    "callbacks = [EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20),\n",
    "               ModelCheckpoint('../shared_train/_model_.h5', monitor='val_loss', mode='min', save_best_only=True)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cp5S9cf4PD4V"
   },
   "outputs": [],
   "source": [
    "# changing input data to numpy array\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lm2YMxYsPD4V",
    "outputId": "701cd91b-dbc8-4068-e912-469b6c2a6b73",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1584 samples, validate on 177 samples\n",
      "Epoch 1/80\n",
      "1584/1584 [==============================] - 88s 55ms/step - loss: 2.5928 - accuracy: 0.2146 - val_loss: 1.7735 - val_accuracy: 0.2486\n",
      "Epoch 2/80\n",
      "1584/1584 [==============================] - 123s 78ms/step - loss: 1.7316 - accuracy: 0.3725 - val_loss: 1.4612 - val_accuracy: 0.4802\n",
      "Epoch 3/80\n",
      "1584/1584 [==============================] - 123s 78ms/step - loss: 1.4712 - accuracy: 0.4729 - val_loss: 1.4339 - val_accuracy: 0.4746\n",
      "Epoch 4/80\n",
      "1584/1584 [==============================] - 92s 58ms/step - loss: 1.2861 - accuracy: 0.5429 - val_loss: 1.1009 - val_accuracy: 0.6328\n",
      "Epoch 5/80\n",
      "1584/1584 [==============================] - 89s 56ms/step - loss: 1.1256 - accuracy: 0.6054 - val_loss: 1.0455 - val_accuracy: 0.6158\n",
      "Epoch 6/80\n",
      "1584/1584 [==============================] - 91s 57ms/step - loss: 0.9526 - accuracy: 0.6660 - val_loss: 0.9227 - val_accuracy: 0.6723\n",
      "Epoch 7/80\n",
      "1584/1584 [==============================] - 93s 59ms/step - loss: 0.8300 - accuracy: 0.7052 - val_loss: 0.8422 - val_accuracy: 0.6949\n",
      "Epoch 8/80\n",
      "1584/1584 [==============================] - 88s 55ms/step - loss: 0.6964 - accuracy: 0.7424 - val_loss: 0.6144 - val_accuracy: 0.7797\n",
      "Epoch 9/80\n",
      "1584/1584 [==============================] - 85s 54ms/step - loss: 0.6026 - accuracy: 0.7809 - val_loss: 0.7598 - val_accuracy: 0.7288\n",
      "Epoch 10/80\n",
      "1584/1584 [==============================] - 89s 56ms/step - loss: 0.5415 - accuracy: 0.8169 - val_loss: 0.5905 - val_accuracy: 0.7966\n",
      "Epoch 11/80\n",
      "1584/1584 [==============================] - 85s 53ms/step - loss: 0.4685 - accuracy: 0.8352 - val_loss: 0.5587 - val_accuracy: 0.7627\n",
      "Epoch 12/80\n",
      "1584/1584 [==============================] - 88s 56ms/step - loss: 0.4136 - accuracy: 0.8630 - val_loss: 0.4669 - val_accuracy: 0.8418\n",
      "Epoch 13/80\n",
      "1584/1584 [==============================] - 91s 58ms/step - loss: 0.3573 - accuracy: 0.8782 - val_loss: 0.4238 - val_accuracy: 0.8531\n",
      "Epoch 14/80\n",
      "1584/1584 [==============================] - 95s 60ms/step - loss: 0.2618 - accuracy: 0.9040 - val_loss: 0.4207 - val_accuracy: 0.8475\n",
      "Epoch 15/80\n",
      "1584/1584 [==============================] - 94s 59ms/step - loss: 0.2488 - accuracy: 0.9116 - val_loss: 0.4156 - val_accuracy: 0.8475\n",
      "Epoch 16/80\n",
      "1584/1584 [==============================] - 95s 60ms/step - loss: 0.2544 - accuracy: 0.9110 - val_loss: 0.3083 - val_accuracy: 0.8983\n",
      "Epoch 17/80\n",
      "1584/1584 [==============================] - 94s 60ms/step - loss: 0.2274 - accuracy: 0.9192 - val_loss: 0.4227 - val_accuracy: 0.8757\n",
      "Epoch 18/80\n",
      "1584/1584 [==============================] - 102s 65ms/step - loss: 0.2045 - accuracy: 0.9331 - val_loss: 0.4853 - val_accuracy: 0.8418\n",
      "Epoch 19/80\n",
      "1584/1584 [==============================] - 102s 64ms/step - loss: 0.1715 - accuracy: 0.9394 - val_loss: 0.3768 - val_accuracy: 0.8870\n",
      "Epoch 20/80\n",
      "1584/1584 [==============================] - 100s 63ms/step - loss: 0.1730 - accuracy: 0.9407 - val_loss: 0.4006 - val_accuracy: 0.8701\n",
      "Epoch 21/80\n",
      "1584/1584 [==============================] - 101s 64ms/step - loss: 0.1416 - accuracy: 0.9457 - val_loss: 0.4165 - val_accuracy: 0.8701\n",
      "Epoch 22/80\n",
      "1584/1584 [==============================] - 102s 64ms/step - loss: 0.1961 - accuracy: 0.9394 - val_loss: 0.4621 - val_accuracy: 0.8814\n",
      "Epoch 23/80\n",
      "1584/1584 [==============================] - 99s 63ms/step - loss: 0.1460 - accuracy: 0.9508 - val_loss: 0.4388 - val_accuracy: 0.8588\n",
      "Epoch 24/80\n",
      "1584/1584 [==============================] - 99s 63ms/step - loss: 0.1354 - accuracy: 0.9552 - val_loss: 0.5645 - val_accuracy: 0.8249\n",
      "Epoch 25/80\n",
      "1584/1584 [==============================] - 102s 65ms/step - loss: 0.1416 - accuracy: 0.9552 - val_loss: 0.3684 - val_accuracy: 0.8757\n",
      "Epoch 26/80\n",
      "1584/1584 [==============================] - 105s 66ms/step - loss: 0.1330 - accuracy: 0.9539 - val_loss: 0.3510 - val_accuracy: 0.8644\n",
      "Epoch 27/80\n",
      "1584/1584 [==============================] - 100s 63ms/step - loss: 0.1022 - accuracy: 0.9640 - val_loss: 0.3487 - val_accuracy: 0.8927\n",
      "Epoch 28/80\n",
      "1584/1584 [==============================] - 99s 62ms/step - loss: 0.1063 - accuracy: 0.9634 - val_loss: 0.4067 - val_accuracy: 0.8927\n",
      "Epoch 29/80\n",
      "1584/1584 [==============================] - 99s 63ms/step - loss: 0.1058 - accuracy: 0.9596 - val_loss: 0.3519 - val_accuracy: 0.8870\n",
      "Epoch 30/80\n",
      "1584/1584 [==============================] - 99s 62ms/step - loss: 0.0861 - accuracy: 0.9672 - val_loss: 0.4241 - val_accuracy: 0.8757\n",
      "Epoch 31/80\n",
      "1584/1584 [==============================] - 99s 62ms/step - loss: 0.0938 - accuracy: 0.9665 - val_loss: 0.3372 - val_accuracy: 0.8814\n",
      "Epoch 32/80\n",
      "1584/1584 [==============================] - 98s 62ms/step - loss: 0.1056 - accuracy: 0.9659 - val_loss: 0.5024 - val_accuracy: 0.8531\n",
      "Epoch 33/80\n",
      "1584/1584 [==============================] - 98s 62ms/step - loss: 0.1270 - accuracy: 0.9539 - val_loss: 0.5259 - val_accuracy: 0.8588\n",
      "Epoch 34/80\n",
      "1584/1584 [==============================] - 98s 62ms/step - loss: 0.1241 - accuracy: 0.9583 - val_loss: 0.6133 - val_accuracy: 0.8588\n",
      "Epoch 35/80\n",
      "1584/1584 [==============================] - 98s 62ms/step - loss: 0.1327 - accuracy: 0.9539 - val_loss: 0.3494 - val_accuracy: 0.9040\n",
      "Epoch 36/80\n",
      "1584/1584 [==============================] - 103s 65ms/step - loss: 0.1315 - accuracy: 0.9545 - val_loss: 0.4057 - val_accuracy: 0.8588\n",
      "Epoch 00036: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x142f4eab348>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model \n",
    "model.fit(X_train, y_train, batch_size=64, epochs=80, validation_data=(X_test, y_test), callbacks=callbacks )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('../shared_train/_model_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "omcS-3_BPD4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../shared_train/feats_task_1\\\\a001.npy',\n",
       " '../shared_train/feats_task_1\\\\a002.npy',\n",
       " '../shared_train/feats_task_1\\\\a003.npy',\n",
       " '../shared_train/feats_task_1\\\\a004.npy',\n",
       " '../shared_train/feats_task_1\\\\a005.npy',\n",
       " '../shared_train/feats_task_1\\\\a006.npy',\n",
       " '../shared_train/feats_task_1\\\\a007.npy',\n",
       " '../shared_train/feats_task_1\\\\a008.npy',\n",
       " '../shared_train/feats_task_1\\\\a009.npy',\n",
       " '../shared_train/feats_task_1\\\\a010.npy',\n",
       " '../shared_train/feats_task_1\\\\a011.npy',\n",
       " '../shared_train/feats_task_1\\\\a012.npy',\n",
       " '../shared_train/feats_task_1\\\\a013.npy',\n",
       " '../shared_train/feats_task_1\\\\a014.npy',\n",
       " '../shared_train/feats_task_1\\\\a015.npy',\n",
       " '../shared_train/feats_task_1\\\\a016.npy',\n",
       " '../shared_train/feats_task_1\\\\a017.npy',\n",
       " '../shared_train/feats_task_1\\\\a018.npy',\n",
       " '../shared_train/feats_task_1\\\\a019.npy',\n",
       " '../shared_train/feats_task_1\\\\a020.npy',\n",
       " '../shared_train/feats_task_1\\\\a021.npy',\n",
       " '../shared_train/feats_task_1\\\\a022.npy',\n",
       " '../shared_train/feats_task_1\\\\a023.npy',\n",
       " '../shared_train/feats_task_1\\\\a024.npy',\n",
       " '../shared_train/feats_task_1\\\\a025.npy',\n",
       " '../shared_train/feats_task_1\\\\a026.npy',\n",
       " '../shared_train/feats_task_1\\\\a027.npy',\n",
       " '../shared_train/feats_task_1\\\\a028.npy',\n",
       " '../shared_train/feats_task_1\\\\a029.npy',\n",
       " '../shared_train/feats_task_1\\\\a030.npy',\n",
       " '../shared_train/feats_task_1\\\\a031.npy',\n",
       " '../shared_train/feats_task_1\\\\a032.npy',\n",
       " '../shared_train/feats_task_1\\\\a033.npy',\n",
       " '../shared_train/feats_task_1\\\\a034.npy',\n",
       " '../shared_train/feats_task_1\\\\a035.npy',\n",
       " '../shared_train/feats_task_1\\\\a036.npy',\n",
       " '../shared_train/feats_task_1\\\\a037.npy',\n",
       " '../shared_train/feats_task_1\\\\a038.npy',\n",
       " '../shared_train/feats_task_1\\\\a039.npy',\n",
       " '../shared_train/feats_task_1\\\\a040.npy',\n",
       " '../shared_train/feats_task_1\\\\a041.npy',\n",
       " '../shared_train/feats_task_1\\\\a042.npy',\n",
       " '../shared_train/feats_task_1\\\\a043.npy',\n",
       " '../shared_train/feats_task_1\\\\a044.npy',\n",
       " '../shared_train/feats_task_1\\\\a045.npy',\n",
       " '../shared_train/feats_task_1\\\\a046.npy',\n",
       " '../shared_train/feats_task_1\\\\a047.npy',\n",
       " '../shared_train/feats_task_1\\\\a048.npy',\n",
       " '../shared_train/feats_task_1\\\\a049.npy',\n",
       " '../shared_train/feats_task_1\\\\a050.npy']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################################### testing model for sample_task_1 ###################################################################3\n",
    "\n",
    "# creating list of file address\n",
    "import glob          \n",
    "input_files = glob.glob(\"../shared_train/feats_task_1/*.npy\")\n",
    "input_files.sort()\n",
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "ndfwEfdePD4i"
   },
   "outputs": [],
   "source": [
    "# making list of input test data and padding it\n",
    "\n",
    "list_2=[]\n",
    "for i in input_files:\n",
    "    a=np.load(i)\n",
    "    a=np.pad(a, ((0,0),(0,401-a.shape[1])))\n",
    "    list_2.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "r8VgJy_APD4k"
   },
   "outputs": [],
   "source": [
    "# converting it to numpy array\n",
    "list_2=np.array(list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "sCAML38sPD4l",
    "outputId": "844a544f-1b34-440b-b6bd-253a07c547ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 3, 2, 4, 0, 0, 7, 2, 2, 3, 0, 2, 3, 7, 2, 8, 6, 7, 1, 0, 8, 3,\n",
       "       1, 2, 0, 4, 4, 7, 4, 6, 7, 7, 3, 6, 6, 2, 0, 1, 8, 1, 5, 4, 2, 8,\n",
       "       2, 6, 6, 7, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final output of numbers\n",
    "y_2=np.argmax(model.predict(list_2),axis=1)\n",
    "y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "enJK-d22PD4m",
    "outputId": "646545d1-41e2-442f-a487-2197b9b34a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_conditioner',\n",
       " 'siren',\n",
       " 'engine_idling',\n",
       " 'jackhammer',\n",
       " 'dog_bark',\n",
       " 'dog_bark',\n",
       " 'street_music',\n",
       " 'engine_idling',\n",
       " 'engine_idling',\n",
       " 'siren',\n",
       " 'dog_bark',\n",
       " 'engine_idling',\n",
       " 'siren',\n",
       " 'street_music',\n",
       " 'engine_idling',\n",
       " 'air_conditioner',\n",
       " 'children_playing',\n",
       " 'street_music',\n",
       " 'gun_shot',\n",
       " 'dog_bark',\n",
       " 'air_conditioner',\n",
       " 'siren',\n",
       " 'gun_shot',\n",
       " 'engine_idling',\n",
       " 'dog_bark',\n",
       " 'jackhammer',\n",
       " 'jackhammer',\n",
       " 'street_music',\n",
       " 'jackhammer',\n",
       " 'children_playing',\n",
       " 'street_music',\n",
       " 'street_music',\n",
       " 'siren',\n",
       " 'children_playing',\n",
       " 'children_playing',\n",
       " 'engine_idling',\n",
       " 'dog_bark',\n",
       " 'gun_shot',\n",
       " 'air_conditioner',\n",
       " 'gun_shot',\n",
       " 'drilling',\n",
       " 'jackhammer',\n",
       " 'engine_idling',\n",
       " 'air_conditioner',\n",
       " 'engine_idling',\n",
       " 'children_playing',\n",
       " 'children_playing',\n",
       " 'street_music',\n",
       " 'engine_idling',\n",
       " 'dog_bark']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final corresponding labels\n",
    "list_2=[]\n",
    "for i in range(len(y_2)):\n",
    "    list_2.append(dict_y[y_2[i]])\n",
    "list_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ViuJT6tkPD4m"
   },
   "outputs": [],
   "source": [
    "# creating list of file names\n",
    "list_1=[]\n",
    "for i in range(len(input_files)):\n",
    "    list_1.append(input_files[i].split('\\\\')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "W7TtqYPQPD4n"
   },
   "outputs": [],
   "source": [
    "# saving result to csv file\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(data={\"col1\": list_1, \"col2\": list_2})\n",
    "df.to_csv(\"./final_output_task_1.csv\", sep=',',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "end sem project (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
