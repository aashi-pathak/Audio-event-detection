{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "87GWZ6PGmMFG"
      },
      "source": [
        "import glob\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import librosa\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import librosa\r\n",
        "import numpy as np\r\n",
        "import pdb\r\n",
        "import string\r\n",
        "from Levenshtein import distance\r\n",
        "import glob\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from scipy import stats"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUKocAvDmkcR"
      },
      "source": [
        "####################################################################  Utilis ###############################################################\r\n",
        "def wav2feat(wavfile):\r\n",
        "    '''\r\n",
        "    Input: audio wav file name\r\n",
        "    Output: Magnitude spectrogram\r\n",
        "    '''\r\n",
        "    x, Fs = librosa.load(wavfile, sr=44100, mono=True) \r\n",
        "    hop = int(0.01 * Fs) # 10ms\r\n",
        "    win = int(0.02 * Fs) # 20ms\r\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\r\n",
        "    return np.abs(X)\r\n",
        "\r\n",
        "def wavs2feat(wavfiles):\r\n",
        "    '''\r\n",
        "    Concatenate the audio files listed in wavfiles\r\n",
        "    Input: list of audio wav file names\r\n",
        "    Output: Magnitude spectrogram of concatenated wav\r\n",
        "    '''\r\n",
        "    x = []\r\n",
        "    for wf in wavfiles:\r\n",
        "        x1, Fs = librosa.load(wf, sr=44100, mono=True)\r\n",
        "        x.append(x1)\r\n",
        "    x = np.hstack(x)\r\n",
        "    hop = int(0.01 * Fs) # 10ms\r\n",
        "    win = int(0.02 * Fs) # 20ms\r\n",
        "    X = librosa.stft(x, n_fft=1024, hop_length=hop, win_length=win, window='hann', center=True, pad_mode='reflect')\r\n",
        "    return np.abs(X)\r\n",
        "\r\n",
        "def read_csv(filename):\r\n",
        "    id_label = {}\r\n",
        "    with open(filename,'r') as fid:\r\n",
        "        for line in fid: # '176787-5-0-27.wav,engine_idling\\n'\r\n",
        "            tokens = line.strip().split(',') # ['176787-5-0-27.wav', 'engine_idling']\r\n",
        "            id_label[tokens[0]] = tokens[1]\r\n",
        "    return id_label\r\n",
        "\r\n",
        "def editDistance(gt, est):\r\n",
        "    '''both are lists of labels\r\n",
        "    E.g. gt is \"dog_bark-street_music-engine_idling\"\r\n",
        "    E.g. est is \"street_music-engine_idling\"\r\n",
        "    '''\r\n",
        "    gttokens = gt.split('-')\r\n",
        "    esttokens = est.split('-')\r\n",
        "    # Map token to char\r\n",
        "    tokenset = list(set(gttokens+esttokens)) # ['dog_bark', 'siren', 'street_music', 'engine_idling']\r\n",
        "    token_char = {}\r\n",
        "    for i in range(len(tokenset)):\r\n",
        "        token_char[tokenset[i]] = string.ascii_uppercase[i]  # {'dog_bark': 'A', 'siren': 'B', 'street_music': 'C', 'engine_idling': 'D'}\r\n",
        "    # convert gt and est to strings\r\n",
        "    gtstr = [token_char[t] for t in gttokens]\r\n",
        "    gtstr = ''.join(gtstr)  # 'BCA'\r\n",
        "    eststr = [token_char[t] for t in esttokens]\r\n",
        "    eststr = ''.join(eststr)  # \r\n",
        "    # Compare\r\n",
        "    editdist = distance(gtstr, eststr) # 1\r\n",
        "    score = 1 - editdist/len(gtstr)\r\n",
        "    return editdist, score\r\n",
        "\r\n",
        "def evals(gtcsv, estcsv, taskid):\r\n",
        "    gt_id_label = read_csv(gtcsv)\r\n",
        "    est_id_label = read_csv(estcsv)\r\n",
        "    score = 0\r\n",
        "    for id in est_id_label:\r\n",
        "        if taskid==1:\r\n",
        "            if est_id_label[id] == gt_id_label[id]:\r\n",
        "                score += 1\r\n",
        "        elif taskid==2:\r\n",
        "            _, ss = editDistance(gt_id_label[id], est_id_label[id])\r\n",
        "            score += ss\r\n",
        "        else:\r\n",
        "            pdb.set_trace()\r\n",
        "            assert False, [\"taskid not correct; it is\", taskid]\r\n",
        "    avgScore = score/len(est_id_label)\r\n",
        "    return avgScore\r\n",
        "\r\n",
        "############################################################################################################################################"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lP5yqz5nVt7"
      },
      "source": [
        "# function for making dict of labels which maps the corresponding class to number \r\n",
        "# function for and dict of numbers which maps the corresponding label\r\n",
        "\r\n",
        "def labels_y(y_csv):\r\n",
        "  labels = {}\r\n",
        "  labels_ = {}\r\n",
        "  j=0\r\n",
        "  for i in y_csv:\r\n",
        "    if y_csv[i]=='class': continue\r\n",
        "    labels[y_csv[i]]=1\r\n",
        "  for i in labels:\r\n",
        "    labels[i]=j\r\n",
        "    j=j+1\r\n",
        "  for i in labels:\r\n",
        "    labels_[labels[i]]=i\r\n",
        "\r\n",
        "  return  labels, labels_"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg6VFP03vc4N"
      },
      "source": [
        "# function to create data which is to be trained\r\n",
        "\r\n",
        "def make_data(X,y):\r\n",
        "  x = []\r\n",
        "  Y = []\r\n",
        "  for j in range(len(X)):\r\n",
        "    for i in range(0, X[j].shape[1]-20, 5):\r\n",
        "      x.append(X[j][:, i:i+20])\r\n",
        "      Y.append(y[j])\r\n",
        "\r\n",
        "  x=np.array(x)\r\n",
        "  Y=np.array(Y)\r\n",
        "  x = np.reshape(x,(len(x), 513*20))\r\n",
        "  Y=np.reshape(Y, (len(Y),))\r\n",
        "  return x,Y"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXFl6ZrUoq8P"
      },
      "source": [
        "y_csv = read_csv('/content/drive/MyDrive/shared_train/labels_train.csv')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_CkpHE4wRun"
      },
      "source": [
        "labels, labels_ = labels_y(y_csv)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQV-FSLCpgPW"
      },
      "source": [
        "f = glob.glob('/content/drive/MyDrive/shared_train/audio_train'+'/*.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV3t1mwmpk1H"
      },
      "source": [
        "# making dataset to train\r\n",
        "\r\n",
        "X=[]\r\n",
        "y=[]\r\n",
        "for F in f:\r\n",
        "  X.append(wav2feat(F))\r\n",
        "  y.append(labels[y_csv[F.split('/')[-1]]])\r\n",
        "\r\n",
        "X_, y_ = make_data(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY0fPU4h20w4"
      },
      "source": [
        "# split data into test and train\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split( X_, y_, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE3HzN6o2HXn",
        "outputId": "d5e36dae-3583-499f-9b07-91e113fd4f74"
      },
      "source": [
        "# traing the model\r\n",
        "\r\n",
        "clf = RandomForestClassifier(n_estimators = 30)\r\n",
        "clf.fit(X_train, y_train)\r\n",
        "\r\n",
        "print ('fit to train new: ', clf.score(X_train, y_train))\r\n",
        "print ('fit to test: ', clf.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit to train new:  0.9999586161231584\n",
            "fit to test:  0.9473618870266914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OogJItEX3DMX"
      },
      "source": [
        "# saving the model for future use\r\n",
        "\r\n",
        "import pickle\r\n",
        "with open('/content/drive/MyDrive/test_2.pickle', \"wb\") as f:\r\n",
        "     pickle.dump(clf, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO0Ox5Qo3bDU"
      },
      "source": [
        "# loading the model\r\n",
        "\r\n",
        "import pickle\r\n",
        "with open('/content/drive/MyDrive/test_2.pickle', \"rb\") as f:\r\n",
        "     clf = pickle.load(f)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMD49D9n5NJY"
      },
      "source": [
        "# function of creating final output of numbers by removing repeated numbers\r\n",
        "\r\n",
        "def final(Yt):\r\n",
        "  yf = []\r\n",
        "  for y in Yt:\r\n",
        "    t =[]\r\n",
        "    i=0\r\n",
        "    a = y[i]\r\n",
        "    b = 1\r\n",
        "    for i in range(1, len(y)):\r\n",
        "      if y[i]==a: b=b+1\r\n",
        "      else :\r\n",
        "        if b>7:\r\n",
        "          t.append(a)\r\n",
        "        a=y[i]\r\n",
        "        b=1\r\n",
        "      if len(t)>1 and t[len(t)-1]==t[len(t)-2]: t=t[:len(t)-1]\r\n",
        "      if i==len(y)-1 and b>7 : t.append(a)\r\n",
        "    if len(t)>1 and t[len(t)-1]==t[len(t)-2]: t=t[:len(t)-1]\r\n",
        "    if len(t)==0: t.append(stats.mode(y))\r\n",
        "    yf.append(t)\r\n",
        "  return yf\r\n",
        "\r\n",
        "\r\n",
        "  # function of converting it to string of labels\r\n",
        "def labels_final(yf, labels):\r\n",
        "  l_f = []\r\n",
        "  for y in yf:\r\n",
        "    str_ = \"\"\r\n",
        "    i=0\r\n",
        "    for a in y:\r\n",
        "      if i!=0: str_=str_+'-'\r\n",
        "      str_ = str_+labels[a]\r\n",
        "      i=i+1\r\n",
        "    l_f.append(str_)\r\n",
        "  return l_f\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf4TtZ_M61c-"
      },
      "source": [
        "############################################# testing model for sample_task_2 #########################################################################\r\n",
        "\r\n",
        "# list of file address\r\n",
        "f = glob.glob('/content/drive/MyDrive/shared_train/sample_test_task2/feats'+'/*.npy')\r\n",
        "f.sort()\r\n",
        "\r\n",
        "# creating list of file names\r\n",
        "F_=[]\r\n",
        "for a in f:\r\n",
        "  F_.append(a.split('/')[-1].split('.')[0])\r\n",
        "\r\n",
        "\r\n",
        "# loading input and breaking it into parts \r\n",
        "# then creating the output it\r\n",
        "Xt = []\r\n",
        "Yt = []\r\n",
        "for F in f:\r\n",
        "  a=np.load(F)\r\n",
        "  Xt = []\r\n",
        "  for i in range(0, a.shape[1]-5, 5):\r\n",
        "    if i+20<a.shape[1]:Xt.append(a[:, i:i+20])\r\n",
        "    else: Xt.append(np.pad(a[:,i:],((0,0),(0,20-len(a[:,i:][0])))))\r\n",
        "  if len(Xt)==0: Xt.append(np.pad(a[:,0:],((0,0),(0,20-len(a[:,0:][0])))))\r\n",
        "  Xt=np.array(Xt)\r\n",
        "  Xt = np.reshape(Xt,(len(Xt), 513*20))\r\n",
        "  Yt.append(clf.predict(Xt))\r\n",
        "\r\n",
        " \r\n",
        "# creating final output \r\n",
        "Yf = final(Yt)\r\n",
        "l_f = labels_final(Yf, labels_)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVQ15n_X8Mfg"
      },
      "source": [
        "# save output to a csv file\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "df = pd.DataFrame(data={\"col1\": F_, \"col2\": l_f})\r\n",
        "df.to_csv('/content/drive/MyDrive/Certificates/file3.csv', sep=',',index=False,header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrnGA3xn8TM1",
        "outputId": "e42cab4c-55fd-4017-bb0f-ce64568ef64b"
      },
      "source": [
        "# print result of sample_tets_task_2\r\n",
        "\r\n",
        "print(evals('/content/drive/MyDrive/shared_train/sample_test_task2/labels.csv','/content/drive/MyDrive/Certificates/file3.csv',2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9416666666666668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjts1nkYboVE"
      },
      "source": [
        "####################################################### final task 2 #######################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTttTQKUbs-K"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# list of file address\r\n",
        "f = glob.glob('/content/drive/MyDrive/test_task2/feats'+'/*.npy')\r\n",
        "f.sort()\r\n",
        "\r\n",
        "# creating list of file names\r\n",
        "F_=[]\r\n",
        "for a in f:\r\n",
        "  F_.append(a.split('/')[-1].split('.')[0])\r\n",
        "\r\n",
        "\r\n",
        "# loading input and breaking it into parts \r\n",
        "# then creating the output it\r\n",
        "Xt = []\r\n",
        "Yt = []\r\n",
        "for F in f:\r\n",
        "  a=np.load(F)\r\n",
        "  Xt = []\r\n",
        "  for i in range(0, a.shape[1]-5, 5):\r\n",
        "    if i+20<a.shape[1]:Xt.append(a[:, i:i+20])\r\n",
        "    else: Xt.append(np.pad(a[:,i:],((0,0),(0,20-len(a[:,i:][0])))))\r\n",
        "  if len(Xt)==0: Xt.append(np.pad(a[:,0:],((0,0),(0,20-len(a[:,0:][0])))))\r\n",
        "  Xt=np.array(Xt)\r\n",
        "  Xt = np.reshape(Xt,(len(Xt), 513*20))\r\n",
        "  Yt.append(clf.predict(Xt))\r\n",
        "\r\n",
        " \r\n",
        "# creating final output \r\n",
        "Yf = final(Yt)\r\n",
        "l_f = labels_final(Yf, labels_)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFJFOvpXcXbi"
      },
      "source": [
        "# save output to a csv file\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "df = pd.DataFrame(data={\"col1\": F_, \"col2\": l_f})\r\n",
        "df.to_csv('/content/drive/MyDrive/Certificates/file3.csv', sep=',',index=False,header=False)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxzMKzMv2BxS",
        "outputId": "d40ad9ee-d993-48d9-d5e8-918c7accf2e3"
      },
      "source": [
        "for l in l_f:\r\n",
        "  print(l)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog_bark-street_music-dog_bark\n",
            "jackhammer-street_music-drilling-dog_bark\n",
            "dog_bark-street_music\n",
            "dog_bark\n",
            "street_music-dog_bark\n",
            "street_music-engine_idling-children_playing-street_music\n",
            "gun_shot-engine_idling-street_music-jackhammer\n",
            "drilling-engine_idling\n",
            "dog_bark-street_music-siren\n",
            "engine_idling-street_music\n",
            "street_music-dog_bark-drilling\n",
            "children_playing-engine_idling-siren-dog_bark\n",
            "dog_bark-drilling\n",
            "engine_idling\n",
            "street_music-drilling-dog_bark-street_music\n",
            "street_music-jackhammer-street_music\n",
            "siren-jackhammer\n",
            "street_music-siren\n",
            "drilling-street_music\n",
            "street_music-air_conditioner-siren-dog_bark-siren-dog_bark\n",
            "dog_bark-street_music-children_playing\n",
            "dog_bark-street_music-drilling\n",
            "jackhammer-drilling-street_music\n",
            "drilling-dog_bark\n",
            "siren-dog_bark-drilling-dog_bark\n",
            "drilling-street_music-drilling\n",
            "street_music-engine_idling-street_music-children_playing-street_music\n",
            "street_music-children_playing-jackhammer\n",
            "dog_bark-engine_idling-dog_bark\n",
            "drilling-street_music\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}